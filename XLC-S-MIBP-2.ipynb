{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a207ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "def read_pssm_file(file_path):\n",
    "    pssm = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines[3:]:\n",
    "#             print(line.split(' '))\n",
    "            line_list = line.split(' ')\n",
    "            line_list = [item for item in line_list if len(item)!=0]\n",
    "            if len(line_list[2:22]) == 0:\n",
    "                break\n",
    "            pssm.extend(list(map(int,line_list[2:22])))\n",
    "    return pssm\n",
    "\n",
    "def getFasta(fasta_path):\n",
    "\n",
    "    fasta_file = fasta_path\n",
    "\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append({\n",
    "            \"id\": record.id,\n",
    "            \"sequence\": str(record.seq)\n",
    "        })\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "\n",
    "        \n",
    "        if sequence[\"sequence\"].find('O') != -1:\n",
    "            print(fasta_path)\n",
    "            continue\n",
    "        if len(sequence[\"sequence\"])>512:\n",
    "            continue\n",
    "\n",
    "        result.append(sequence[\"sequence\"])\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getPssm(dim):\n",
    "    folder_path = r\"./PSSMs\"\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "    pssm_labels = []\n",
    "    pssm_features = []\n",
    "    temp_label = 0\n",
    "    queDict = dict()\n",
    "    for file in files:\n",
    "        sub_files = os.listdir(folder_path + '/' + file)\n",
    "        print(len(pssm_features))\n",
    "        if file == 'NMBP':\n",
    "            temp_label = 0\n",
    "        else:\n",
    "#             continue\n",
    "            temp_label = 1\n",
    "        queDict[file] = []\n",
    "        print(temp_label,file)\n",
    "        for sub_file in sub_files:\n",
    "            end_file_path = folder_path + '/' + file + '/' + sub_file\n",
    "            temp = read_pssm_file(end_file_path)\n",
    "            if len(temp) > 10240:\n",
    "                continue\n",
    "            pssm_features.append(temp)\n",
    "            pssm_labels.append(temp_label)\n",
    "            queDict[file].append(sub_file.split('.')[0])\n",
    "#             print(queDict)\n",
    "    \n",
    "    new_features = []\n",
    "    for i in range(len(pssm_features)):\n",
    "        pssm_features[i].extend([0 for j in range(10240-len(pssm_features[i]))])\n",
    "        new_features.append(pssm_features[i])\n",
    "#         print(new_features)\n",
    "#         new_features.append(pssm_features[i].extend([0]*(10240-len(features[i]))))\n",
    "\n",
    "\n",
    "    n_components =dim\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    X_pca = pca.fit_transform(new_features)\n",
    "    \n",
    "    return X_pca,queDict\n",
    "\n",
    "\n",
    "\n",
    "def getData(que_dict):\n",
    "    folder_path = r'./Reads'\n",
    "\n",
    "    label = []\n",
    "    feature = []\n",
    "\n",
    "    folders = os.listdir(folder_path)\n",
    "    cnt = 0\n",
    "    flag = 0\n",
    "    for folder in folders:\n",
    "        filds = os.listdir(folder_path + '/' + folder)\n",
    "        if folder == 'NMBP':\n",
    "            flag = 0\n",
    "        else:\n",
    "            flag = 1\n",
    "        for fild in filds:\n",
    "            if fild.split('.')[0] not in que_dict[folder]:\n",
    "\n",
    "                continue\n",
    "            false_feature = getFasta(folder_path + '/' + folder + '/' + fild)\n",
    "            \n",
    "            false_feature = ' '.join(false_feature[0])\n",
    "            feature.append(false_feature)\n",
    "            label.append(flag)\n",
    "    \n",
    "    return feature,label\n",
    "    \n",
    "    \n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import torch\n",
    "def mix_data(encoded_data,X_pca):\n",
    "    X_pca = cp.deepcopy(X_pca)\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for i in range(len(X_pca)):\n",
    "        list_encoded = encoded_data['input_ids'][i].tolist()\n",
    "        list_X_pca = list(X_pca[i])\n",
    "        list_X_pca.extend(list_encoded)\n",
    "        input_ids.append(list_X_pca)\n",
    "        attention_mask_list = encoded_data['attention_mask'][i].tolist()\n",
    "        attention_mask_listtemp = [1 for i in range(1024-514)]\n",
    "        attention_mask_listtemp.extend(attention_mask_list)\n",
    "        attention_mask.append(attention_mask_listtemp)\n",
    "    \n",
    "    return input_ids,attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d533b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1 Ca\n",
      "2950\n",
      "1 Cu\n",
      "3358\n",
      "1 Fe\n",
      "4886\n",
      "1 K\n",
      "5602\n",
      "1 Mn\n",
      "6632\n",
      "0 NMBP\n",
      "10730\n",
      "1 Zn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy as cp\n",
    "X_pca,queDict = getPssm(512)\n",
    "featrue,label = getData(queDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6e88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_featrue = []\n",
    "for i in featrue:\n",
    "    before_featrue.append(i.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9a8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(before_featrue, vector_size=50)\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce650ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_feture = []\n",
    "maxmax = -1\n",
    "for i in range(len(before_featrue)):\n",
    "    temp = []\n",
    "    for j in range(len(before_featrue[i])):\n",
    "        temp.extend(word_vectors[before_featrue[i][j]])\n",
    "    maxmax = max(maxmax,len(temp))\n",
    "    temp.extend([0 for item in range(25600 - len(temp))])\n",
    "    after_feture.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=512)\n",
    "\n",
    "after_feture_pca = pca.fit_transform(after_feture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e298a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_feture_pca = after_feture_pca.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b16b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total_feture = []\n",
    "for i in range(len(X_pca)):\n",
    "    after_feture_pca_copy = cp.deepcopy(after_feture_pca[i])\n",
    "    after_feture_pca_copy.extend(X_pca[i])\n",
    "    all_total_feture.append(after_feture_pca_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49532069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "all_total_feture_normalized = scaler.fit_transform(all_total_feture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_total_feture_normalized, label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85966ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_svm = svm.SVC()\n",
    "\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"ACC:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_DecisionTreeClassifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf_DecisionTreeClassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_DecisionTreeClassifier = clf_DecisionTreeClassifier.predict(X_test)\n",
    "\n",
    "accuracy_DecisionTreeClassifier = accuracy_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "print(\"ACCï¼š\", accuracy_DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89883e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model_RandomForestClassifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "model_RandomForestClassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_RandomForestClassifier = model_RandomForestClassifier.predict(X_test)\n",
    "\n",
    "accuracy_RandomForestClassifier = accuracy_score(y_test, y_pred_RandomForestClassifier)\n",
    "print(\"ACCï¼š\", accuracy_RandomForestClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09497c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model_catboost = CatBoostClassifier(iterations=2500, depth=7, learning_rate=0.06, loss_function='Logloss')\n",
    "\n",
    "model_catboost.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "y_pred_prob_catboost = model_catboost.predict(X_test, prediction_type='Probability')[:, 1]  \n",
    "y_pred_catboost = [1 if pred > 0.5 else 0 for pred in y_pred_prob_catboost] \n",
    "\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "print(f'ACC: {accuracy_catboost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c79e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error', \n",
    "    'boosting_type': 'gbdt',\n",
    "#     'num_leaves': 31,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "num_round = 5000\n",
    "bst_lightgbm = lgb.train(params, train_data, num_round, valid_sets=[test_data],verbose_eval=100)\n",
    "\n",
    "y_pred_prob_lightgbm = bst_lightgbm.predict(X_test, num_iteration=bst_lightgbm.best_iteration)\n",
    "y_pred_lightgbm = [1 if pred > 0.5 else 0 for pred in y_pred_prob_lightgbm] \n",
    "\n",
    "accuracy_lightgbm = accuracy_score(y_test, y_pred_lightgbm)\n",
    "print(f'Accuracy: {accuracy_lightgbm}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a66e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.03\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "num_round = 3000\n",
    "bst_xgboost = xgb.train(params, dtrain, num_round, evals=watchlist, verbose_eval=100)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "y_pred_prob_xgboost = bst_xgboost.predict(dtest)  \n",
    "y_pred_xgboost = [1 if pred > 0.5 else 0 for pred in y_pred_prob_xgboost]  \n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "print(f'Accuracy: {accuracy_xgboost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab33ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feture_train = []\n",
    "for i in range(len(y_pred_prob_xgboost)):\n",
    "    \n",
    "    class_feture_train.append([y_pred_prob_xgboost[i] , y_pred_prob_lightgbm[i] , y_pred_prob_catboost[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_feture_train\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "y_class_feture_train = cp.deepcopy(y_test)\n",
    "\n",
    "X_train_vote, X_test_vote, y_train_vote, y_test_vote = train_test_split(class_feture_train, y_class_feture_train, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "clf = svm.SVC()  \n",
    "\n",
    "\n",
    "clf.fit(X_train_vote, y_train_vote)\n",
    "\n",
    "y_pred_vote = clf.predict(X_test_vote)\n",
    "\n",
    "accuracy_vote = accuracy_score(y_test_vote, y_pred_vote)\n",
    "print(\"ACC:\", accuracy_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"colorblind\", 7)\n",
    "\n",
    "\n",
    "\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y_test_vote, y_pred_vote)\n",
    "\n",
    "\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y_test, y_pred_svm.tolist())\n",
    "\n",
    "\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "\n",
    "fpr3, tpr3, thresholds3 = roc_curve(y_test, y_pred_DecisionTreeClassifier)\n",
    "\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "\n",
    "fpr4, tpr4, thresholds4 = roc_curve(y_test, y_pred_RandomForestClassifier)\n",
    "\n",
    "roc_auc4 = auc(fpr4, tpr4)\n",
    "\n",
    "\n",
    "fpr5, tpr5, thresholds5 = roc_curve(y_test, y_pred_xgboost)\n",
    "\n",
    "roc_auc5 = auc(fpr5, tpr5)\n",
    "\n",
    "\n",
    "fpr6, tpr6, thresholds6 = roc_curve(y_test, y_pred_lightgbm)\n",
    "\n",
    "roc_auc6 = auc(fpr6, tpr6)\n",
    "\n",
    "fpr7, tpr7, thresholds7 = roc_curve(y_test, y_pred_catboost)\n",
    "\n",
    "roc_auc7 = auc(fpr7, tpr7)\n",
    "\n",
    "plt.rcParams['font.size'] = 15  \n",
    "\n",
    "# ç»˜åˆ¶ROCæ›²çº¿\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr1, tpr1, lw=2, label=f'XLC-S-MIBP ROC curve (area = {roc_auc1:.2f})', color=colors[0])\n",
    "plt.plot(fpr2, tpr2, lw=2, label=f'SVM ROC curve (area = {roc_auc2:.2f})', color=colors[1])\n",
    "plt.plot(fpr3, tpr3, lw=2, label=f'DT ROC curve (area = {roc_auc3:.2f})', color=colors[2])\n",
    "plt.plot(fpr4, tpr4, lw=2, label=f'RF ROC curve (area = {roc_auc4:.2f})', color=colors[3])\n",
    "plt.plot(fpr5, tpr5, lw=2, label=f'xgboost ROC curve (area = {roc_auc5:.2f})', color=colors[4])\n",
    "plt.plot(fpr6, tpr6, lw=2, label=f'lightgbm ROC curve (area = {roc_auc6:.2f})', color=colors[5])\n",
    "plt.plot(fpr7, tpr7, lw=2, label=f'catboost ROC curve (area = {roc_auc7:.2f})', color=colors[6])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=18)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.savefig(r'./images/2-Receiver Operating Characteristic (ROC) Curve.png', dpi=500)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_vote, y_pred_vote)\n",
    "\n",
    "\n",
    "classes = ['Non-MIBP','MIBP']\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes,annot_kws={\"size\": 14})\n",
    "plt.xlabel('Predicted Labels', fontsize=15)\n",
    "plt.ylabel('True Labels', fontsize=15)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "\n",
    "plt.savefig(r'./images/2-Confusion Matrix.png', dpi=500) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "precision_vote = precision_score(y_test_vote, y_pred_vote)\n",
    "recall_vote = recall_score(y_test_vote, y_pred_vote)\n",
    "f1_vote = f1_score(y_test_vote, y_pred_vote)\n",
    "print('mymodel')\n",
    "print(\"Precision: {:.4f}\".format(precision_vote))\n",
    "print(\"Recall: {:.4f}\".format(recall_vote))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_vote))\n",
    "\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "print('svm')\n",
    "print(\"Precision: {:.4f}\".format(precision_svm))\n",
    "print(\"Recall: {:.4f}\".format(recall_svm))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_svm))\n",
    "\n",
    "\n",
    "precision_DecisionTreeClassifier = precision_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "recall_DecisionTreeClassifier = recall_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "f1_DecisionTreeClassifier = f1_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "print('DecisionTreeClassifier')\n",
    "print(\"Precision: {:.4f}\".format(precision_DecisionTreeClassifier))\n",
    "print(\"Recall: {:.4f}\".format(recall_DecisionTreeClassifier))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_DecisionTreeClassifier))\n",
    "\n",
    "\n",
    "precision_RandomForestClassifier = precision_score(y_test, y_pred_RandomForestClassifier)\n",
    "recall_RandomForestClassifier = recall_score(y_test, y_pred_RandomForestClassifier)\n",
    "f1_RandomForestClassifier = f1_score(y_test, y_pred_RandomForestClassifier)\n",
    "print('RandomForestClassifier')\n",
    "print(\"Precision: {:.4f}\".format(precision_RandomForestClassifier))\n",
    "print(\"Recall: {:.4f}\".format(recall_RandomForestClassifier))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_RandomForestClassifier))\n",
    "\n",
    "precision_xgboost = precision_score(y_test, y_pred_xgboost)\n",
    "recall_xgboost = recall_score(y_test, y_pred_xgboost)\n",
    "f1_xgboost = f1_score(y_test, y_pred_xgboost)\n",
    "print('xgboost')\n",
    "print(\"Precision: {:.4f}\".format(precision_xgboost))\n",
    "print(\"Recall: {:.4f}\".format(recall_xgboost))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_xgboost))\n",
    "\n",
    "\n",
    "precision_lightgbm = precision_score(y_test, y_pred_lightgbm)\n",
    "recall_lightgbm = recall_score(y_test, y_pred_lightgbm)\n",
    "f1_lightgbm = f1_score(y_test, y_pred_lightgbm)\n",
    "print('lightgbm')\n",
    "print(\"Precision: {:.4f}\".format(precision_lightgbm))\n",
    "print(\"Recall: {:.4f}\".format(recall_lightgbm))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_lightgbm))\n",
    "\n",
    "\n",
    "precision_catboost = precision_score(y_test, y_pred_catboost)\n",
    "recall_catboost = recall_score(y_test, y_pred_catboost)\n",
    "f1_catboost = f1_score(y_test, y_pred_catboost)\n",
    "print('catboost')\n",
    "print(\"Precision: {:.4f}\".format(precision_catboost))\n",
    "print(\"Recall: {:.4f}\".format(recall_catboost))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "categories = ['XLC-S-MIBP', 'SVM', 'DT', 'RF', 'xgboost', 'lightgbm', 'catboost']\n",
    "num_categories = len(categories)\n",
    "values_set1 = [accuracy_vote, accuracy_svm, accuracy_DecisionTreeClassifier, accuracy_RandomForestClassifier, \n",
    "               accuracy_xgboost, accuracy_lightgbm, accuracy_catboost]\n",
    "values_set2 = [precision_vote, precision_svm, precision_DecisionTreeClassifier, precision_RandomForestClassifier, \n",
    "               precision_xgboost, precision_lightgbm, precision_catboost]\n",
    "values_set3 = [recall_vote, recall_svm, recall_DecisionTreeClassifier, recall_RandomForestClassifier, \n",
    "               recall_xgboost, recall_lightgbm, recall_catboost]\n",
    "values_set4 = [f1_vote, f1_svm, f1_DecisionTreeClassifier, f1_RandomForestClassifier, \n",
    "               f1_xgboost, f1_lightgbm, f1_catboost]\n",
    "\n",
    "bar_width = 0.21\n",
    "colors = sns.color_palette(\"colorblind\", 4)\n",
    "\n",
    "r = np.arange(num_categories)\n",
    "r1 = r - 1.5*bar_width\n",
    "r2 = r - 0.5*bar_width\n",
    "r3 = r + 0.5*bar_width\n",
    "r4 = r + 1.5*bar_width\n",
    "\n",
    "plt.bar(r1, values_set1, color=colors[0], width=bar_width, edgecolor='grey', label='ACC')\n",
    "plt.bar(r2, values_set2, color=colors[1], width=bar_width, edgecolor='grey', label='P')\n",
    "plt.bar(r3, values_set3, color=colors[2], width=bar_width, edgecolor='grey', label='R')\n",
    "plt.bar(r4, values_set4, color=colors[3], width=bar_width, edgecolor='grey', label='F1')\n",
    "\n",
    "plt.xlabel('Categories', fontsize=15)\n",
    "plt.ylabel('Values', fontsize=15)\n",
    "\n",
    "plt.ylim(0.6, 1.0)\n",
    "\n",
    "plt.xticks(r, categories, fontsize=8)  \n",
    "plt.title('Model Evaluation', fontsize=18)\n",
    "\n",
    "plt.legend(loc='upper right',fontsize=12)\n",
    "\n",
    "plt.savefig(r'./images/2-Model Evaluation.png', dpi=500) \n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b7fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
