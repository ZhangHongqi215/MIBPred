{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e412e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "def read_pssm_file(file_path):\n",
    "    pssm = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines[3:]:\n",
    "            line_list = line.split(' ')\n",
    "            line_list = [item for item in line_list if len(item)!=0]\n",
    "            if len(line_list[2:22]) == 0:\n",
    "                break\n",
    "            pssm.extend(list(map(int,line_list[2:22])))\n",
    "    return pssm\n",
    "\n",
    "def getFasta(fasta_path):\n",
    "    fasta_file = fasta_path\n",
    "\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append({\n",
    "            \"id\": record.id,\n",
    "            \"sequence\": str(record.seq)\n",
    "        })\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for sequence in sequences:\n",
    "\n",
    "        \n",
    "        if sequence[\"sequence\"].find('O') != -1:\n",
    "            print(fasta_path)\n",
    "            continue\n",
    "        if len(sequence[\"sequence\"])>512:\n",
    "            continue\n",
    "\n",
    "        result.append(sequence[\"sequence\"])\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getPssm(dim):\n",
    "    folder_path = r\"./PSSMs\"\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "    pssm_labels = []\n",
    "    pssm_features = []\n",
    "\n",
    "    temp_label = -1\n",
    "    queDict = dict()\n",
    "    for file in files:\n",
    "        sub_files = os.listdir(folder_path + '/' + file)\n",
    "        if file == 'NMBP':\n",
    "            continue\n",
    "        else:\n",
    "            temp_label += 1\n",
    "        queDict[file] = []\n",
    "        print(temp_label,file)\n",
    "        for sub_file in sub_files:\n",
    "            end_file_path = folder_path + '/' + file + '/' + sub_file\n",
    "            temp = read_pssm_file(end_file_path)\n",
    "            if len(temp) > 10240:\n",
    "                continue\n",
    "            pssm_features.append(temp)\n",
    "            pssm_labels.append(temp_label)\n",
    "            queDict[file].append(sub_file.split('.')[0])\n",
    "    \n",
    "    new_features = []\n",
    "    for i in range(len(pssm_features)):\n",
    "        pssm_features[i].extend([0 for j in range(10240-len(pssm_features[i]))])\n",
    "        new_features.append(pssm_features[i])\n",
    "\n",
    "    n_components =dim\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    X_pca = pca.fit_transform(new_features)\n",
    "    \n",
    "    return X_pca,queDict\n",
    "\n",
    "\n",
    "\n",
    "def getData(que_dict):\n",
    "    folder_path = r'./Reads'\n",
    "\n",
    "    label = []\n",
    "    feature = []\n",
    "\n",
    "    folders = os.listdir(folder_path)\n",
    "    cnt = 0\n",
    "    flag = -1\n",
    "    for folder in folders:\n",
    "        filds = os.listdir(folder_path + '/' + folder)\n",
    "        if folder == 'NMBP':\n",
    "            continue\n",
    "        else:\n",
    "            flag += 1\n",
    "        print(flag,folder)\n",
    "        for fild in filds:\n",
    "            if fild.split('.')[0] not in que_dict[folder]:\n",
    "\n",
    "                continue\n",
    "            false_feature = getFasta(folder_path + '/' + folder + '/' + fild)\n",
    "            \n",
    "            false_feature = ' '.join(false_feature[0])\n",
    "            feature.append(false_feature)\n",
    "            label.append(flag)\n",
    "    \n",
    "    return feature,label\n",
    "    \n",
    "    \n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import torch\n",
    "def mix_data(encoded_data,X_pca):\n",
    "    X_pca = cp.deepcopy(X_pca)\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for i in range(len(X_pca)):\n",
    "        list_encoded = encoded_data['input_ids'][i].tolist()\n",
    "        list_X_pca = list(X_pca[i])\n",
    "        list_X_pca.extend(list_encoded)\n",
    "        input_ids.append(list_X_pca)\n",
    "        attention_mask_list = encoded_data['attention_mask'][i].tolist()\n",
    "        attention_mask_listtemp = [1 for i in range(1024-514)]\n",
    "        attention_mask_listtemp.extend(attention_mask_list)\n",
    "        attention_mask.append(attention_mask_listtemp)\n",
    "    \n",
    "    return input_ids,attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee41e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ca\n",
      "1 Cu\n",
      "2 Fe\n",
      "3 K\n",
      "4 Mn\n",
      "5 Zn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy as cp\n",
    "X_pca,queDict = getPssm(512)\n",
    "featrue,label = getData(queDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_featrue = []\n",
    "for i in featrue:\n",
    "    before_featrue.append(i.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8028bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(before_featrue, vector_size=50)\n",
    "\n",
    "word_vectors = model.wv\n",
    "\n",
    "vector = word_vectors['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_feture = []\n",
    "after_label = []\n",
    "remove_index = []\n",
    "maxmax = -1\n",
    "for i in range(len(before_featrue)):\n",
    "    temp = []\n",
    "    continue_flag = 0\n",
    "    for j in range(len(before_featrue[i])):\n",
    "        try:\n",
    "            temp.extend(word_vectors[before_featrue[i][j]])\n",
    "        except:\n",
    "            remove_index.append(i)\n",
    "            continue_flag = 1\n",
    "            break\n",
    "    if continue_flag == 1:\n",
    "        continue\n",
    "    temp.extend([0 for item in range(25600 - len(temp))])\n",
    "    after_feture.append(temp)\n",
    "    after_label.append(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20651d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_X_pca = []\n",
    "for i in range(len(X_pca)):\n",
    "    if i in remove_index:\n",
    "        continue\n",
    "    else:\n",
    "        after_X_pca.append(X_pca[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa09576",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=512)\n",
    "\n",
    "after_feture_pca = pca.fit_transform(after_feture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_feture_pca = after_feture_pca.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total_feture = []\n",
    "for i in range(len(after_X_pca)):\n",
    "    after_feture_pca_copy = cp.deepcopy(after_feture_pca[i])\n",
    "    after_feture_pca_copy.extend(after_X_pca[i])\n",
    "    all_total_feture.append(after_feture_pca_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56db3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "all_total_feture_normalized = scaler.fit_transform(all_total_feture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68901b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_total_feture_normalized, after_label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ced6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_svm = svm.SVC(kernel='linear')  \n",
    "\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"ACC:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "clf_DecisionTreeClassifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf_DecisionTreeClassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_DecisionTreeClassifier = clf_DecisionTreeClassifier.predict(X_test)\n",
    "\n",
    "accuracy_DecisionTreeClassifier = accuracy_score(y_test, y_pred_DecisionTreeClassifier)\n",
    "print(\"ACCï¼š\", accuracy_DecisionTreeClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb33e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_RandomForestClassifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model_RandomForestClassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_RandomForestClassifier = model_RandomForestClassifier.predict(X_test)\n",
    "\n",
    "accuracy_RandomForestClassifier = accuracy_score(y_test, y_pred_RandomForestClassifier)\n",
    "print(\"ACCï¼š\", accuracy_RandomForestClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad470a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_catboost = CatBoostClassifier(iterations=5000, depth=8, learning_rate=0.09)\n",
    "\n",
    "model_catboost.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "y_pred_prob_catboost = model_catboost.predict_proba(X_test)\n",
    "y_pred_catboost = np.argmax(y_pred_prob_catboost, axis=1) \n",
    "\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "print(f'Accuracy: {accuracy_catboost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fd2c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',  \n",
    "    'num_class': 6,  \n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "\n",
    "num_round = 2500\n",
    "bst_lightgbm = lgb.train(params, train_data, num_round, valid_sets=[test_data],verbose_eval=100)\n",
    "\n",
    "y_pred_prob_lightgbm = bst_lightgbm.predict(X_test, num_iteration=bst_lightgbm.best_iteration) \n",
    "y_pred_lightgbm = np.argmax(y_pred_prob_lightgbm, axis=1)  \n",
    "\n",
    "\n",
    "accuracy_lightgbm = accuracy_score(y_test, y_pred_lightgbm)\n",
    "print(f'Accuracy: {accuracy_lightgbm}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17473c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 6, \n",
    "    'learning_rate': 0.01\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "num_round = 4500\n",
    "bst_xgboost = xgb.train(params, dtrain, num_round, evals=watchlist, verbose_eval=100)\n",
    "\n",
    "\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "y_pred_prob_xgboost = bst_xgboost.predict(dtest, output_margin=True) \n",
    "y_pred_xgboost = np.argmax(y_pred_prob_xgboost, axis=1)  \n",
    "\n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "print(f'Accuracy: {accuracy_xgboost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feture_train = []\n",
    "y_pred_prob_xgboost = y_pred_prob_xgboost.tolist()\n",
    "y_pred_prob_lightgbm = y_pred_prob_lightgbm.tolist()\n",
    "y_pred_prob_catboost = y_pred_prob_catboost.tolist()\n",
    "y_class_feture_train = cp.deepcopy(y_test)\n",
    "for i in range(len(y_pred_prob_xgboost)):\n",
    "    class_feture_train.append(y_pred_prob_xgboost[i] + y_pred_prob_lightgbm[i] + y_pred_prob_catboost[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_feture_train\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_vote, X_test_vote, y_train_vote, y_test_vote = train_test_split(class_feture_train, y_class_feture_train, test_size=0.3, random_state=42)\n",
    "\n",
    "clf_vote = svm.SVC()  \n",
    "\n",
    "clf_vote.fit(X_train_vote, y_train_vote)\n",
    "\n",
    "y_pred_vote = clf_vote.predict(X_test_vote)\n",
    "\n",
    "accuracy_vote = accuracy_score(y_test_vote, y_pred_vote)\n",
    "print(\"ACC:\", accuracy_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_vote, y_pred_vote)\n",
    "\n",
    "classes = ['Ca','Cu','Fe','K','Mn','Zn']\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes,annot_kws={\"size\": 14})\n",
    "plt.xlabel('Predicted Labels', fontsize=15)\n",
    "plt.ylabel('True Labels', fontsize=15)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.savefig(r'./images/6-Confusion Matrix.png', dpi=500)  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "precision_vote = precision_score(y_test_vote, y_pred_vote, average='weighted')\n",
    "recall_vote = recall_score(y_test_vote, y_pred_vote, average='weighted')\n",
    "f1_vote = f1_score(y_test_vote, y_pred_vote, average='weighted')\n",
    "print('mymodel')\n",
    "print(\"Precision: {:.4f}\".format(precision_vote))\n",
    "print(\"Recall: {:.4f}\".format(recall_vote))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_vote))\n",
    "\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "print('svm')\n",
    "print(\"Precision: {:.4f}\".format(precision_svm))\n",
    "print(\"Recall: {:.4f}\".format(recall_svm))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_svm))\n",
    "\n",
    "precision_DecisionTreeClassifier = precision_score(y_test, y_pred_DecisionTreeClassifier, average='weighted')\n",
    "recall_DecisionTreeClassifier = recall_score(y_test, y_pred_DecisionTreeClassifier, average='weighted')\n",
    "f1_DecisionTreeClassifier = f1_score(y_test, y_pred_DecisionTreeClassifier, average='weighted')\n",
    "print('DecisionTreeClassifier')\n",
    "print(\"Precision: {:.4f}\".format(precision_DecisionTreeClassifier))\n",
    "print(\"Recall: {:.4f}\".format(recall_DecisionTreeClassifier))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_DecisionTreeClassifier))\n",
    "\n",
    "\n",
    "precision_RandomForestClassifier = precision_score(y_test, y_pred_RandomForestClassifier, average='weighted')\n",
    "recall_RandomForestClassifier = recall_score(y_test, y_pred_RandomForestClassifier, average='weighted')\n",
    "f1_RandomForestClassifier = f1_score(y_test, y_pred_RandomForestClassifier, average='weighted')\n",
    "print('RandomForestClassifier')\n",
    "print(\"Precision: {:.4f}\".format(precision_RandomForestClassifier))\n",
    "print(\"Recall: {:.4f}\".format(recall_RandomForestClassifier))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_RandomForestClassifier))\n",
    "\n",
    "\n",
    "precision_xgboost = precision_score(y_test, y_pred_xgboost, average='weighted')\n",
    "recall_xgboost = recall_score(y_test, y_pred_xgboost, average='weighted')\n",
    "f1_xgboost = f1_score(y_test, y_pred_xgboost, average='weighted')\n",
    "print('xgboost')\n",
    "print(\"Precision: {:.4f}\".format(precision_xgboost))\n",
    "print(\"Recall: {:.4f}\".format(recall_xgboost))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_xgboost))\n",
    "\n",
    "precision_lightgbm = precision_score(y_test, y_pred_lightgbm, average='weighted')\n",
    "recall_lightgbm = recall_score(y_test, y_pred_lightgbm, average='weighted')\n",
    "f1_lightgbm = f1_score(y_test, y_pred_lightgbm, average='weighted')\n",
    "print('lightgbm')\n",
    "print(\"Precision: {:.4f}\".format(precision_lightgbm))\n",
    "print(\"Recall: {:.4f}\".format(recall_lightgbm))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_lightgbm))\n",
    "\n",
    "precision_catboost = precision_score(y_test, y_pred_catboost, average='weighted')\n",
    "recall_catboost = recall_score(y_test, y_pred_catboost, average='weighted')\n",
    "f1_catboost = f1_score(y_test, y_pred_catboost, average='weighted')\n",
    "print('catboost')\n",
    "print(\"Precision: {:.4f}\".format(precision_catboost))\n",
    "print(\"Recall: {:.4f}\".format(recall_catboost))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176016db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "categories = ['XLC-S-MIBP', 'SVM', 'DT', 'RF', 'xgboost', 'lightgbm', 'catboost']\n",
    "num_categories = len(categories)\n",
    "values_set1 = [accuracy_vote, accuracy_svm, accuracy_DecisionTreeClassifier, accuracy_RandomForestClassifier, \n",
    "               accuracy_xgboost, accuracy_lightgbm, accuracy_catboost]\n",
    "values_set2 = [precision_vote, precision_svm, precision_DecisionTreeClassifier, precision_RandomForestClassifier, \n",
    "               precision_xgboost, precision_lightgbm, precision_catboost]\n",
    "values_set3 = [recall_vote, recall_svm, recall_DecisionTreeClassifier, recall_RandomForestClassifier, \n",
    "               recall_xgboost, recall_lightgbm, recall_catboost]\n",
    "values_set4 = [f1_vote, f1_svm, f1_DecisionTreeClassifier, f1_RandomForestClassifier, \n",
    "               f1_xgboost, f1_lightgbm, f1_catboost]\n",
    "\n",
    "bar_width = 0.21\n",
    "\n",
    "r = np.arange(num_categories)\n",
    "r1 = r - 1.5*bar_width\n",
    "r2 = r - 0.5*bar_width\n",
    "r3 = r + 0.5*bar_width\n",
    "r4 = r + 1.5*bar_width\n",
    "\n",
    "colors = sns.color_palette(\"colorblind\", 4)\n",
    "\n",
    "plt.bar(r1, values_set1, color=colors[0], width=bar_width, edgecolor='grey', label='ACC')\n",
    "plt.bar(r2, values_set2, color=colors[1], width=bar_width, edgecolor='grey', label='P')\n",
    "plt.bar(r3, values_set3, color=colors[2], width=bar_width, edgecolor='grey', label='R')\n",
    "plt.bar(r4, values_set4, color=colors[3], width=bar_width, edgecolor='grey', label='F1')\n",
    "\n",
    "plt.xlabel('Categories', fontsize=15)\n",
    "plt.ylabel('Values', fontsize=15)\n",
    "\n",
    "plt.ylim(0.55, 1.0)\n",
    "\n",
    "plt.xticks(r, categories, fontsize=8)  \n",
    "plt.title('Model Evaluation', fontsize=18)\n",
    "\n",
    "plt.legend(loc='upper right',fontsize=12)\n",
    "\n",
    "\n",
    "plt.savefig(r'./images/6-Model Evaluation.png', dpi=500) \n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
